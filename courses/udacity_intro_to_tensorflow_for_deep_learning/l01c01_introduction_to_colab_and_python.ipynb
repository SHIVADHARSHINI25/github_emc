{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHIVADHARSHINI25/github_emc/blob/main/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class CrowdDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images = []\n",
        "        for f in os.listdir(root_dir):\n",
        "            if f.endswith('.jpg') or f.endswith('.png'):\n",
        "                base = os.path.splitext(f)[0]\n",
        "                mat_name = f\"GT_{base}.mat\"\n",
        "                mat_path = os.path.join(root_dir, mat_name)\n",
        "                if os.path.exists(mat_path):\n",
        "                    self.images.append(f)\n",
        "                else:\n",
        "                    print(f\"⚠️  Skipping {f} — no matching {mat_name}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "        mat_name = f\"GT_{base_name}.mat\"\n",
        "\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        mat_path = os.path.join(self.root_dir, mat_name)\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Load density map from .mat\n",
        "        mat = sio.loadmat(mat_path)\n",
        "\n",
        "        # Assumes the .mat contains 'density' key — adjust if needed\n",
        "        if 'density' in mat:\n",
        "            density = mat['density']\n",
        "        else:\n",
        "            raise KeyError(f\"'density' not found in {mat_path}\")\n",
        "\n",
        "        density = density.astype(np.float32)\n",
        "        density_img = Image.fromarray(density)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            density_img = TF.resize(density_img, [256, 256])\n",
        "            density_img = TF.to_tensor(density_img)\n",
        "\n",
        "        return image, density_img\n"
      ],
      "metadata": {
        "id": "ElJK31F9Z4oz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw4Q4gsGbQth",
        "outputId": "998c66c4-79ef-4a5b-877d-d3ff39c7bcae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 0\n",
            "Val samples: 0\n",
            "Test samples: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/CrowdDataset/train'\n",
        "val_path   = '/content/drive/MyDrive/CrowdDataset/val'\n",
        "test_path  = '/content/drive/MyDrive/CrowdDataset/test'\n"
      ],
      "metadata": {
        "id": "pee0Xb6Ihor8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Train Files:\", os.listdir(train_path))\n",
        "print(\"Val Files:\", os.listdir(val_path))\n",
        "print(\"Test Files:\", os.listdir(test_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOyTTKHkhtq3",
        "outputId": "5e024a90-001c-4fe5-c6b4-b50cbb09bc95"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Files: ['ground_truth', 'images']\n",
            "Val Files: ['ground_truth', 'images']\n",
            "Test Files: ['growth_truth', 'images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import torch\n",
        "\n",
        "class CrowdDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "\n",
        "        for f in os.listdir(root_dir):\n",
        "            if f.endswith('.jpg') or f.endswith('.png'):\n",
        "                img_path = os.path.join(root_dir, f)\n",
        "                base_name = os.path.splitext(f)[0]\n",
        "                mat_name = f\"GT_{base_name}.mat\"\n",
        "                mat_path = os.path.join(root_dir, mat_name)\n",
        "\n",
        "                if os.path.exists(mat_path):\n",
        "                    self.images.append((img_path, mat_path))\n",
        "                else:\n",
        "                    print(f\"⚠️ Skipping {f} — no matching {mat_name}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mat_path = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        # Assume 'image_info' is in .mat (you may need to adapt this!)\n",
        "        points = mat['image_info'][0][0][0][0][0]\n",
        "        target = torch.tensor(points.shape[0], dtype=torch.float32)  # crowd count\n",
        "\n",
        "        return image, target\n"
      ],
      "metadata": {
        "id": "4j515qLLhx4u"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = CrowdDataset(train_path, transform=transform)\n",
        "val_dataset   = CrowdDataset(val_path, transform=transform)\n",
        "test_dataset  = CrowdDataset(test_path, transform=transform)\n",
        "\n",
        "# Check the lengths\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=8)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "7zuchB7hh4c2",
        "outputId": "4b90a28c-034b-4418-e14a-b5364dd193b4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 0\n",
            "Val samples: 0\n",
            "Test samples: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1158350899.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test samples: {len(test_dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mval_loader\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtest_loader\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = CrowdDataset(train_path, transform=transform)\n",
        "val_dataset = CrowdDataset(val_path, transform=transform)\n",
        "test_dataset = CrowdDataset(test_path, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UAblLeXdawi1",
        "outputId": "859ac871-2a92-4659-c171-d356552d5473"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️  Skipping IMG_67.jpg — no matching GT_IMG_67.mat\n",
            "⚠️  Skipping IMG_65.jpg — no matching GT_IMG_65.mat\n",
            "⚠️  Skipping IMG_68.jpg — no matching GT_IMG_68.mat\n",
            "⚠️  Skipping IMG_64.jpg — no matching GT_IMG_64.mat\n",
            "⚠️  Skipping IMG_61.jpg — no matching GT_IMG_61.mat\n",
            "⚠️  Skipping IMG_62.jpg — no matching GT_IMG_62.mat\n",
            "⚠️  Skipping IMG_73.jpg — no matching GT_IMG_73.mat\n",
            "⚠️  Skipping IMG_74.jpg — no matching GT_IMG_74.mat\n",
            "⚠️  Skipping IMG_78.jpg — no matching GT_IMG_78.mat\n",
            "⚠️  Skipping IMG_76.jpg — no matching GT_IMG_76.mat\n",
            "⚠️  Skipping IMG_77.jpg — no matching GT_IMG_77.mat\n",
            "⚠️  Skipping IMG_75.jpg — no matching GT_IMG_75.mat\n",
            "⚠️  Skipping IMG_79.jpg — no matching GT_IMG_79.mat\n",
            "⚠️  Skipping IMG_80.jpg — no matching GT_IMG_80.mat\n",
            "⚠️  Skipping IMG_72.jpg — no matching GT_IMG_72.mat\n",
            "⚠️  Skipping IMG_81.jpg — no matching GT_IMG_81.mat\n",
            "⚠️  Skipping IMG_63.jpg — no matching GT_IMG_63.mat\n",
            "⚠️  Skipping IMG_66.jpg — no matching GT_IMG_66.mat\n",
            "⚠️  Skipping IMG_71.jpg — no matching GT_IMG_71.mat\n",
            "⚠️  Skipping IMG_69.jpg — no matching GT_IMG_69.mat\n",
            "⚠️  Skipping IMG_70.jpg — no matching GT_IMG_70.mat\n",
            "⚠️  Skipping IMG_101.jpg — no matching GT_IMG_101.mat\n",
            "⚠️  Skipping IMG_100.jpg — no matching GT_IMG_100.mat\n",
            "⚠️  Skipping IMG_102.jpg — no matching GT_IMG_102.mat\n",
            "⚠️  Skipping IMG_128.jpg — no matching GT_IMG_128.mat\n",
            "⚠️  Skipping IMG_126.jpg — no matching GT_IMG_126.mat\n",
            "⚠️  Skipping IMG_124.jpg — no matching GT_IMG_124.mat\n",
            "⚠️  Skipping IMG_129.jpg — no matching GT_IMG_129.mat\n",
            "⚠️  Skipping IMG_123.jpg — no matching GT_IMG_123.mat\n",
            "⚠️  Skipping IMG_121.jpg — no matching GT_IMG_121.mat\n",
            "⚠️  Skipping IMG_122.jpg — no matching GT_IMG_122.mat\n",
            "⚠️  Skipping IMG_125.jpg — no matching GT_IMG_125.mat\n",
            "⚠️  Skipping IMG_12.jpg — no matching GT_IMG_12.mat\n",
            "⚠️  Skipping IMG_120.jpg — no matching GT_IMG_120.mat\n",
            "⚠️  Skipping IMG_119.jpg — no matching GT_IMG_119.mat\n",
            "⚠️  Skipping IMG_114.jpg — no matching GT_IMG_114.mat\n",
            "⚠️  Skipping IMG_115.jpg — no matching GT_IMG_115.mat\n",
            "⚠️  Skipping IMG_112.jpg — no matching GT_IMG_112.mat\n",
            "⚠️  Skipping IMG_113.jpg — no matching GT_IMG_113.mat\n",
            "⚠️  Skipping IMG_116.jpg — no matching GT_IMG_116.mat\n",
            "⚠️  Skipping IMG_118.jpg — no matching GT_IMG_118.mat\n",
            "⚠️  Skipping IMG_108.jpg — no matching GT_IMG_108.mat\n",
            "⚠️  Skipping IMG_117.jpg — no matching GT_IMG_117.mat\n",
            "⚠️  Skipping IMG_107.jpg — no matching GT_IMG_107.mat\n",
            "⚠️  Skipping IMG_105.jpg — no matching GT_IMG_105.mat\n",
            "⚠️  Skipping IMG_106.jpg — no matching GT_IMG_106.mat\n",
            "⚠️  Skipping IMG_104.jpg — no matching GT_IMG_104.mat\n",
            "⚠️  Skipping IMG_103.jpg — no matching GT_IMG_103.mat\n",
            "⚠️  Skipping IMG_13.jpg — no matching GT_IMG_13.mat\n",
            "⚠️  Skipping IMG_127.jpg — no matching GT_IMG_127.mat\n",
            "⚠️  Skipping IMG_130.jpg — no matching GT_IMG_130.mat\n",
            "⚠️  Skipping IMG_131.jpg — no matching GT_IMG_131.mat\n",
            "⚠️  Skipping IMG_58.jpg — no matching GT_IMG_58.mat\n",
            "⚠️  Skipping IMG_51.jpg — no matching GT_IMG_51.mat\n",
            "⚠️  Skipping IMG_57.jpg — no matching GT_IMG_57.mat\n",
            "⚠️  Skipping IMG_60.jpg — no matching GT_IMG_60.mat\n",
            "⚠️  Skipping IMG_59.jpg — no matching GT_IMG_59.mat\n",
            "⚠️  Skipping IMG_48.jpg — no matching GT_IMG_48.mat\n",
            "⚠️  Skipping IMG_43.jpg — no matching GT_IMG_43.mat\n",
            "⚠️  Skipping IMG_55.jpg — no matching GT_IMG_55.mat\n",
            "⚠️  Skipping IMG_44.jpg — no matching GT_IMG_44.mat\n",
            "⚠️  Skipping IMG_56.jpg — no matching GT_IMG_56.mat\n",
            "⚠️  Skipping IMG_50.jpg — no matching GT_IMG_50.mat\n",
            "⚠️  Skipping IMG_46.jpg — no matching GT_IMG_46.mat\n",
            "⚠️  Skipping IMG_41.jpg — no matching GT_IMG_41.mat\n",
            "⚠️  Skipping IMG_45.jpg — no matching GT_IMG_45.mat\n",
            "⚠️  Skipping IMG_52.jpg — no matching GT_IMG_52.mat\n",
            "⚠️  Skipping IMG_53.jpg — no matching GT_IMG_53.mat\n",
            "⚠️  Skipping IMG_47.jpg — no matching GT_IMG_47.mat\n",
            "⚠️  Skipping IMG_49.jpg — no matching GT_IMG_49.mat\n",
            "⚠️  Skipping IMG_54.jpg — no matching GT_IMG_54.mat\n",
            "⚠️  Skipping IMG_42.jpg — no matching GT_IMG_42.mat\n",
            "⚠️  Skipping IMG_40.jpg — no matching GT_IMG_40.mat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3013155364.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrowdDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHI3vyhv5p85"
      },
      "source": [
        "## **Introduction to Colab and Python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVi775ZJ2bsy"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8YVA_634OFk"
      },
      "source": [
        "Welcome to this Colab where you will get a quick introduction to the Python programming language and the environment used for the course's exercises: Colab.\n",
        "\n",
        "Colab is a Python development environment that runs in the browser using Google Cloud.\n",
        "\n",
        "For example, to print \"Hello World\", just hover the mouse over [ ] and press the play button to the upper left. Or press shift-enter to execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9uIpOS2zx7k"
      },
      "outputs": [],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwJGmDrQ0EoB"
      },
      "source": [
        "## Functions, Conditionals, and Iteration\n",
        "Let's create a Python function, and call it from a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRllo2HLfXiu"
      },
      "outputs": [],
      "source": [
        "def HelloWorldXY(x, y):\n",
        "  if (x < 10):\n",
        "    print(\"Hello World, x was < 10\")\n",
        "  elif (x < 20):\n",
        "    print(\"Hello World, x was >= 10 but < 20\")\n",
        "  else:\n",
        "    print(\"Hello World, x was >= 20\")\n",
        "  return x + y\n",
        "\n",
        "for i in range(8, 25, 5):  # i=8, 13, 18, 23 (start, stop, step)\n",
        "  print(\"--- Now running with i: {}\".format(i))\n",
        "  r = HelloWorldXY(i,i)\n",
        "  print(\"Result from HelloWorld: {}\".format(r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHNmDCh0JpVP"
      },
      "outputs": [],
      "source": [
        "print(HelloWorldXY(1,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiZG7uhm8qCF"
      },
      "source": [
        "Easy, right?\n",
        "\n",
        "If you want a loop starting at 0 to 2 (exclusive) you could do any of the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8YQN1H41L-Y"
      },
      "outputs": [],
      "source": [
        "print(\"Iterate over the items. `range(2)` is like a list [0,1].\")\n",
        "for i in range(2):\n",
        "  print(i)\n",
        "\n",
        "print(\"Iterate over an actual list.\")\n",
        "for i in [0,1]:\n",
        "  print(i)\n",
        "\n",
        "print(\"While works\")\n",
        "i = 0\n",
        "while i < 2:\n",
        "  print(i)\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIgmFZq4zszl"
      },
      "outputs": [],
      "source": [
        "print(\"Python supports standard key words like continue and break\")\n",
        "while True:\n",
        "  print(\"Entered while\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QyOUhFw1OUX"
      },
      "source": [
        "## Numpy and lists\n",
        "Python has lists built into the language.\n",
        "However, we will use a library called numpy for this.\n",
        "Numpy gives you lots of support functions that are useful when doing Machine Learning.\n",
        "\n",
        "Here, you will also see an import statement. This statement makes the entire numpy package available and we can access those symbols using the abbreviated 'np' syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Dxk4q-jzEy4"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Make numpy available using np.\n",
        "\n",
        "# Create a numpy array, and append an element\n",
        "a = np.array([\"Hello\", \"World\"])\n",
        "a = np.append(a, \"!\")\n",
        "print(\"Current array: {}\".format(a))\n",
        "print(\"Printing each element\")\n",
        "for i in a:\n",
        "  print(i)\n",
        "\n",
        "print(\"\\nPrinting each element and their index\")\n",
        "for i,e in enumerate(a):\n",
        "  print(\"Index: {}, was: {}\".format(i, e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTa8_9G3LV03"
      },
      "outputs": [],
      "source": [
        "print(\"\\nShowing some basic math on arrays\")\n",
        "b = np.array([0,1,4,3,2])\n",
        "print(\"Max: {}\".format(np.max(b)))\n",
        "print(\"Average: {}\".format(np.average(b)))\n",
        "print(\"Max index: {}\".format(np.argmax(b)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YaGj5n4LW7P"
      },
      "outputs": [],
      "source": [
        "print(\"\\nYou can print the type of anything\")\n",
        "print(\"Type of b: {}, type of b[0]: {}\".format(type(b), type(b[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6ilVhi9LXn_"
      },
      "outputs": [],
      "source": [
        "print(\"\\nUse numpy to create a [3,3] dimension array with random number\")\n",
        "c = np.random.rand(3, 3)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Q-DkFCLYGA"
      },
      "outputs": [],
      "source": [
        "print(\"\\nYou can print the dimensions of arrays\")\n",
        "print(\"Shape of a: {}\".format(a.shape))\n",
        "print(\"Shape of b: {}\".format(b.shape))\n",
        "print(\"Shape of c: {}\".format(c.shape))\n",
        "print(\"...Observe, Python uses both [0,1,2] and (0,1,2) to specify lists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Jk4dG91dvD"
      },
      "source": [
        "## Colab Specifics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0cGd8sHEmKi"
      },
      "source": [
        "Colab is a virtual machine you can access directly. To run commands at the VM's terminal, prefix the line with an exclamation point (!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLkfhyzq0W2y"
      },
      "outputs": [],
      "source": [
        "print(\"\\nDoing $ls on filesystem\")\n",
        "!ls -l\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR2WTN1cOZ1n"
      },
      "outputs": [],
      "source": [
        "print(\"Install numpy\")  # Just for test, numpy is actually preinstalled in all Colab instances\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuWRpQdatAIU"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Create a code cell underneath this text cell and add code to:\n",
        "\n",
        "\n",
        "*   List the path of the current directory (pwd)\n",
        "* Go to / (cd) and list the content (ls -l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU-cJbMCR61P"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "!cd /\n",
        "!ls -l\n",
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b5jv0ouFREV"
      },
      "source": [
        "All usage of Colab in this course is completely free or charge. Even GPU usage is provided free of charge for some hours of usage every day.\n",
        "\n",
        "**Using GPUs**\n",
        "* Many of the exercises in the course executes more quickly by using GPU runtime: Runtime | Change runtime type | Hardware accelerator | GPU\n",
        "\n",
        "**Some final words on Colab**\n",
        "*   You execute each cell in order, you can edit & re-execute cells if you want\n",
        "*   Sometimes, this could have unintended consequences. For example, if you add a dimension to an array and execute the cell multiple times, then the cells after may not work. If you encounter problem reset your environment:\n",
        "  *   Runtime -> Restart runtime... Resets your Python shell\n",
        "  *   Runtime -> Restart all runtimes... Will reset the Colab image, and get you back to a 100% clean environment\n",
        "* You can also clear the output in the Colab by doing: Edit -> Clear all outputs\n",
        "* Colabs in this course are loaded from GitHub. Save to your Google Drive if you want a copy with your code/output: File -> Save a copy in Drive...\n",
        "\n",
        "**Learn More**\n",
        "*   Check out [this](https://www.youtube.com/watch?v=inN8seMm7UI&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=3) episode of #CodingTensorFlow, and don't forget to subscribe to the YouTube channel ;)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "975dbeba",
        "outputId": "3218bcfb-06b0-4d4a-cc34-4b9d45740932"
      },
      "source": [
        "import os\n",
        "\n",
        "train_image_path = os.path.join(train_path, 'images')\n",
        "train_gt_path = os.path.join(train_path, 'ground_truth')\n",
        "val_image_path = os.path.join(val_path, 'images')\n",
        "val_gt_path = os.path.join(val_path, 'ground_truth')\n",
        "test_image_path = os.path.join(test_path, 'images')\n",
        "test_gt_path = os.path.join(test_path, 'ground_truth')\n",
        "\n",
        "print(f\"Train Images: {os.listdir(train_image_path)[:10]}\") # Print first 10 files\n",
        "print(f\"Train Ground Truth: {os.listdir(train_gt_path)[:10]}\") # Print first 10 files\n",
        "print(f\"Val Images: {os.listdir(val_image_path)[:10]}\") # Print first 10 files\n",
        "print(f\"Val Ground Truth: {os.listdir(val_gt_path)[:10]}\") # Print first 10 files\n",
        "print(f\"Test Images: {os.listdir(test_image_path)[:10]}\") # Print first 10 files\n",
        "print(f\"Test Ground Truth: {os.listdir(test_gt_path)[:10]}\") # Print first 10 files"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: ['IMG_68.jpg', 'IMG_62.jpg', 'IMG_74.jpg', 'IMG_72.jpg', 'IMG_71.jpg', 'IMG_69.jpg', 'IMG_66.jpg', 'IMG_70.jpg', 'IMG_65.jpg', 'IMG_63.jpg']\n",
            "Train Ground Truth: ['GT_IMG_81.mat', 'GT_IMG_80.mat', 'GT_IMG_74.mat', 'GT_IMG_73.mat', 'GT_IMG_79.mat', 'GT_IMG_77.mat', 'GT_IMG_76.mat', 'GT_IMG_75.mat', 'GT_IMG_78.mat', 'GT_IMG_72.mat']\n",
            "Val Images: ['IMG_62.jpg', 'IMG_76.jpg', 'IMG_67.jpg', 'IMG_74.jpg', 'IMG_68.jpg', 'IMG_61.jpg', 'IMG_70.jpg', 'IMG_63.jpg', 'IMG_73.jpg', 'IMG_66.jpg']\n",
            "Val Ground Truth: ['GT_IMG_81.mat', 'GT_IMG_79.mat', 'GT_IMG_77.mat', 'GT_IMG_80.mat', 'GT_IMG_74.mat', 'GT_IMG_69.mat', 'GT_IMG_76.mat', 'GT_IMG_75.mat', 'GT_IMG_72.mat', 'GT_IMG_78.mat']\n",
            "Test Images: ['IMG_40.jpg', 'IMG_41.jpg', 'IMG_46.jpg', 'IMG_49.jpg', 'IMG_42.jpg', 'IMG_53.jpg', 'IMG_47.jpg', 'IMG_52.jpg', 'IMG_45.jpg', 'IMG_60.jpg']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CrowdDataset/test/ground_truth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2342531528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Val Ground Truth: {os.listdir(val_gt_path)[:10]}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Print first 10 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Images: {os.listdir(test_image_path)[:10]}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Print first 10 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Ground Truth: {os.listdir(test_gt_path)[:10]}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Print first 10 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CrowdDataset/test/ground_truth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04SqXZC8ioTr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l01c01_introduction_to_colab_and_python.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}